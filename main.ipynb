{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import keras\n",
    "import umap\n",
    "import altair as alt\n",
    "import json\n",
    "import pickle as pk\n",
    "from weblogo import *\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import utils.metrics as utils_metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Convolution1D, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, MaxPool1D, Dropout, LSTM, Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.convolutional import UpSampling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Layer\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import utils.data_processing as dp\n",
    "import utils.visualization as viz\n",
    "import utils.models as models\n",
    "import utils.set_env as se\n",
    "import utils.metrics as um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_res(data_dict, network_dict, w, n_class, iteration, viz, acc_only=False):\n",
    "    ep_dict = {}\n",
    "    df_tmp = data_dict['df_train'].copy().reset_index(drop=True)\n",
    "    for i, k in enumerate(data_dict['vc_train'].index):\n",
    "        idx = df_tmp[df_tmp['antigen.epitope'] == k].index[0]\n",
    "        tmp = data_dict['y_enc_train'][idx:idx+1]\n",
    "        ep_dict[i] = tmp\n",
    "\n",
    "    res_tmp = {}\n",
    "    for k, v in ep_dict.items():\n",
    "        ep_tmp = np.tile(v, (data_dict['X_test'].shape[0],1,1))\n",
    "        nll_out = network_dict['NLL'].predict([data_dict['X_test'], ep_tmp])\n",
    "        res_tmp[k] = nll_out\n",
    "\n",
    "    res_tmp_train = {}\n",
    "    for k, v in ep_dict.items():\n",
    "        ep_tmp = np.tile(v, (data_dict['X_train'].shape[0],1,1))\n",
    "        nll_out = network_dict['NLL'].predict([data_dict['X_train'], ep_tmp])\n",
    "        res_tmp_train[k] = nll_out\n",
    "\n",
    "    to_stack = []\n",
    "    to_stack_train = []\n",
    "    for v in res_tmp.values():\n",
    "        to_stack.append(v)\n",
    "    for v in res_tmp_train.values():\n",
    "        to_stack_train.append(v)\n",
    "    \n",
    "    stack = np.vstack(to_stack)\n",
    "    max_likelihood_out = np.argmin(stack, axis=0)\n",
    "    \n",
    "    test_cat = to_categorical(max_likelihood_out)\n",
    "\n",
    "    stack_train = np.vstack(to_stack_train)\n",
    "    max_likelihood_out_train = np.argmin(stack_train, axis=0)\n",
    "    train_cat = to_categorical(max_likelihood_out_train)\n",
    "\n",
    "    max_out = confusion_matrix(max_likelihood_out, data_dict['y_cls_test']).transpose()\n",
    "\n",
    "    max_out_train = confusion_matrix(max_likelihood_out_train, data_dict['y_cls_train']).transpose()\n",
    "\n",
    "    #alpha = get_alpha(data_dict['y_cls_train'], max_likelihood_out_train, w, n_class)\n",
    "    \n",
    "    if viz:\n",
    "        um.viz_conf_mat(max_out_train, data_dict['vc_train'], 'Confusion Matrix Train {}'.format(iteration), acc_only)\n",
    "        acc = um.viz_conf_mat(max_out, data_dict['vc_train'], 'Confusion Matrix Test {}'.format(iteration), acc_only)\n",
    "    else:\n",
    "        acc = um.viz_conf_mat(max_out, data_dict['vc_train'], 'Confusion Matrix Test {}'.format(iteration), acc_only)\n",
    "    return max_likelihood_out_train, max_likelihood_out, train_cat, test_cat, res_tmp, stack, acc, to_stack, to_stack_train, stack_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "reducer = umap.UMAP(n_neighbors=15)\n",
    "\n",
    "TCR_PAD_LEN = 20\n",
    "EP_PAD_LEN = 10\n",
    "NCH = 6\n",
    "TCR_SHAPE= (TCR_PAD_LEN, NCH)\n",
    "EP_SHAPE = (EP_PAD_LEN, NCH)\n",
    "paths = se.make_paths()\n",
    "\n",
    "aa_vec = se.get_aa_vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup = pk.load(open('df_dedup_FINAL.pk', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dedup['cdr3'] = df_dedup['cdr3_fixed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bg_groom = pk.load(open('df_dryad.pk', 'rb'))\n",
    "\n",
    "df_bg_groom['antigen.epitope'] = ' '\n",
    "\n",
    "df_bg_groom = df_bg_groom[~df_bg_groom['cdr3'].isin(df_dedup['cdr3'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes_list = [2, 3, 4, 5]\n",
    "neg_list = [0.5]\n",
    "n_runs = 5\n",
    "class_epoch_dict = {\n",
    "    2: 250,\n",
    "    3: 180,\n",
    "    4: 140,\n",
    "    5: 120\n",
    "}\n",
    "\n",
    "\n",
    "neg = 0.5\n",
    "groom = True\n",
    "total_dict_groom = {}\n",
    "for n_classes in n_classes_list:\n",
    "    for neg in neg_list:\n",
    "        for sample in ['over']:\n",
    "            total_dict_groom[(n_classes, neg, sample)] = {'acc': [],\n",
    "                                                          'auc_dicts': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/250 | Loss: 0.49563834071159363\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ed96be3abd99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0;31m#    n_epoch = 700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     test_tmp = models.train(network_dict_neg, data_dict, 128, n_epoch, 10, choice_idx=None, \n\u001b[0;32m---> 28\u001b[0;31m                                             name='train_img/profile_{}_{}_{}.png'.format(n_classes, neg, sample), auto_stop_n=100)\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0mep_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mdf_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'df_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/song/songlab2/alanluu2/TCR2Vec/workspace/utils/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_dict, data_dict, batch_size, epochs, period, choice_idx, name, auto_stop_n)\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0my_enc_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_enc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0my_cls_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_cls_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_enc_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cls_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_cls_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;31m#print(f'Epoch {i+1}/{epochs} | Batch: {j+1}/{n_batches} | Loss: {loss}', end='\\r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apps/software/Keras/2.0.8-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1762\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apps/software/Keras/2.0.8-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/Keras-2.0.8-py3.6.egg/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apps/software/Tensorflow-GPU/1.2.1-IGB-gcc-4.9.4-Python-3.6.1/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for r in range(1):\n",
    "    for j in range(n_runs):\n",
    "        for n_classes in n_classes_list:\n",
    "            for neg in neg_list:\n",
    "                for sample in ['over']:\n",
    "                    if groom:\n",
    "                        df_filt_dedup10 = df_dedup\n",
    "                    else:\n",
    "                        df_filt_dedup10 = df_filt_dedup[df_filt_dedup['antigen.epitope'].apply(len) <= 10]\n",
    "\n",
    "                    vc10 = df_filt_dedup10['antigen.epitope'].value_counts()\n",
    "\n",
    "                    df_top = df_filt_dedup10[df_filt_dedup10['antigen.epitope'].isin(vc10.index[:n_classes])]\n",
    "\n",
    "                    df_bg_groom = df_bg_groom.sample(frac=1, replace=False)\n",
    "                    df2_first = df_bg_groom[:70000]\n",
    "\n",
    "                    df2_second = df_bg_groom[70000:80000]\n",
    "                    split_dict = dp.split_train_neg(df_top, 0.8, 0, df2_first, neg, True, True, sample)\n",
    "                    data_dict = dp.make_data_dict_neg(split_dict, aa_vec=aa_vec, tcr_pad_len=20, ep_pad_len=10)\n",
    "                    network_dict_neg = models.make_full_network_neg(None)\n",
    "                    n_epoch = class_epoch_dict[n_classes]\n",
    "                    #if sample == 'over':\n",
    "                    #    n_epoch = 175\n",
    "                    #elif sample == 'geo':\n",
    "                    #    n_epoch = 700\n",
    "                    test_tmp = models.train(network_dict_neg, data_dict, 128, n_epoch, 10, choice_idx=None, \n",
    "                                            name='train_img/profile_{}_{}_{}.png'.format(n_classes, neg, sample), auto_stop_n=100)\n",
    "                    ep_dict = {}\n",
    "                    df_tmp = data_dict['df_train'].copy().reset_index(drop=True)\n",
    "                    for i, k in enumerate(data_dict['vc_train'].index):\n",
    "                        idx = df_tmp[df_tmp['antigen.epitope'] == k].index[0]\n",
    "                        tmp = data_dict['y_enc_train'][idx:idx+1]\n",
    "                        ep_dict[i] = tmp\n",
    "\n",
    "                    res_tmp = {}\n",
    "                    for k, v in ep_dict.items():\n",
    "                        ep_tmp = np.tile(v, (data_dict['X_test'].shape[0],1,1))\n",
    "                        nll_out = network_dict_neg['NLL'].predict([data_dict['X_test'], ep_tmp])\n",
    "                        res_tmp[k] = nll_out\n",
    "\n",
    "                    to_stack = []\n",
    "                    for v in res_tmp.values():\n",
    "                        to_stack.append(v)\n",
    "\n",
    "                    stack = np.vstack(to_stack)\n",
    "                    max_likelihood_out = np.argmin(stack, axis=0)\n",
    "\n",
    "                    valid_idx = np.where(data_dict['y_cls_test'] != -1)[0]\n",
    "\n",
    "                    max_l_out_3 = max_likelihood_out[valid_idx]\n",
    "                    cls_test_3 = data_dict['y_cls_test'][valid_idx]\n",
    "\n",
    "                    max_out = confusion_matrix(max_l_out_3, cls_test_3).transpose()\n",
    "\n",
    "                    acc = um.viz_conf_mat(max_out, data_dict['vc_train'], 'Confusion Matrix Test {}'.format(10), False, (17,8))\n",
    "                    total_dict_groom[(n_classes, neg, sample)]['acc'].append(acc)\n",
    "\n",
    "                    new_dict = {}\n",
    "                    n_classes = df_top['antigen.epitope'].value_counts().shape[0]\n",
    "                    roc_dict = {}\n",
    "                    for k in range(n_classes):\n",
    "                        ep_tmp = np.tile(ep_dict[k], (df2_second['cdr3'].shape[0],1,1))\n",
    "                        X_neg = dp.encode_seq_array(df2_second['cdr3'], aa_vec, True, TCR_PAD_LEN)\n",
    "                        nll_out = -1*network_dict_neg['NLL'].predict([X_neg, ep_tmp])\n",
    "                        neg_score = list(nll_out)\n",
    "                        #viz_status = True\n",
    "                        #acc_onlay = False\n",
    "                        #out = vis_res(data_dict, network_dict, None, 10, 1, viz_status, acc_only)\n",
    "                        pos_score = []\n",
    "                        #neg_score = []\n",
    "                        for i, elem in enumerate(data_dict['y_cls_test']):\n",
    "                            if elem == k:\n",
    "                                pos_score.append(-1*stack[elem,i])\n",
    "                        score = np.array(pos_score + neg_score)\n",
    "                        y = [1]*len(pos_score) + [0]*len(neg_score)\n",
    "                        roc_data = roc_curve(y, score, pos_label=1)\n",
    "                        roc_dict[k] = roc_data\n",
    "                        auc_score = auc(roc_data[0], roc_data[1])\n",
    "                        new_dict[k] = auc_score\n",
    "                    pk.dump(roc_dict, open('results/n{}_roc_{}.pk'.format(n_classes, j), 'wb'))\n",
    "\n",
    "                    total_dict_groom[(n_classes, neg, sample)]['auc_dicts'].append(new_dict)\n",
    "                    print((n_classes, neg, sample), total_dict_groom[(n_classes, neg, sample)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
